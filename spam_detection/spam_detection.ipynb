{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "## Description\n",
    "#### This is one of the assignments from course CS 431/631 (Data-intensive Distributed Analytics) at University of Waterloo.\n",
    "#### This assignment focuses on using big data framework to do something with machine learning.\n",
    "#### Some modifications have been made to improve the presentation on this platform.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "For here, use the Spark installation in the CS451 course account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "import findspark, random\n",
    "findspark.init(\"/u/cs451/packages/spark\")\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext(appName=\"YourTest\", master=\"local[2]\", conf=SparkConf().set('spark.ui.port', random.randrange(4000,5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "---\n",
    "#### Overview\n",
    "**Goal:** Use Python and Spark to perform spam detection.   The first thing is to build spam prediction models, using training data sets and stochastic gradient descent (SGD).   The second is to use these models to predict whether the documents in a test data set are spam.\n",
    "The stochastic gradient descent technique that will be used is based on [a paper](http://arxiv.org/abs/1004.5168) by Cormack, Smucker and Clarke.  \n",
    "**Files needed:** `spamminess.py`, training and test datasets in '/u/cs451/public_html/spam/'\n",
    "\n",
    "#### Training a Spam Classification Models\n",
    "To build a spam classification model, start with a training data set.   Each instance in the training set represents a single document, and is labeled to indicate whether that document should be considered to be spam or ham.\n",
    "An instance looks like this:\n",
    "```\n",
    "clueweb09-en0094-20-13546 spam 387908 697162 426572 161118 688171 ...\n",
    "```\n",
    "The first field, `clueweb09-en0094-20-13546`, is the (unique) document name.   The second field is the label, indicating whether the document should be considered spam (as in this example) or ham.   The remaining fields are integers representing *features* present in the document.   In this case, the features are hashed byte 4-grams, represented as integers.   Each training data set is stored as a text file, with one instance per line.   The training files have been preloaded into the directory `/u/cs451/public_html/spam`.   They are:\n",
    "* `spam.train.group_x.txt`   (25 MB)\n",
    "* `spam.train.group_y.txt`   (20 MB)\n",
    "* `spam.train.britney.txt`   (766 MB)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 1:\n",
    "\n",
    "The first task is to write a sequential SGD model trainer in Python (no Spark).   For our purposes, a model associates a *weight* with each feature.   The model trainer decides what these weights should be, based on the training instances.  Since the model trainer is based on SGD, the trainer should behave like this:\n",
    "```\n",
    "for each training instance T\n",
    "   predict whether T is spam or ham using the weights of the current model\n",
    "   update the model weights by comparing T's predicted label with its actual label\n",
    "```\n",
    "Of course, the important part is how to update the model.\n",
    "\n",
    "In [the paper](http://arxiv.org/abs/1004.5168), the model is used to assign a \"spamminess\" score to a document.   Documents with positive spamminess are predicted to be spam.   Those with negative spamminess are predicted to be ham.  The spamminess of a document $D$ is simply the sum of the weights (from the model) of each of the document's features:\n",
    "\\begin{equation}\n",
    "spamminess(D) = \\sum_{f \\in D}{w(f)}\n",
    "\\end{equation}\n",
    "where $w(f)$ is the weight assocated with feature $f$.\n",
    "\n",
    "The Python module `spamminess.py` defines a function `spamminess(F,W)` which computes this quantity.   This function takes two arguments, `F` and `W`.  `F` is a list of features (integers) associated to the document whose spamminess we want to compute, and `W` is a dictionary representing the current model.  `W` maps features ($f$) to their weights ($w(f)$) under the model.\n",
    "\n",
    "The cell below presents the partial pseudo-code that shows how to implement the SGD model trainer defined by Cormack, Smucker, and Clarke.   It reads the training instances one at a time from one of the training files, and uses them to adjust the model weights.   The task here is to turn this pseudo-code into actual runnable Python code that can\n",
    "be used to learn a model from any one of the training files. Implement the function `sequential_SGD()` that takes as input a model (`w`), the training dataset and a value for the update parameter `delta`, and returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "\n",
    "def sequential_SGD(model, training_dataset='/u/cs451/public_html/spam/spam.train.group_x.txt', delta = 0.002):\n",
    "    # open one of the training files - defaults to group_x\n",
    "    with open(training_dataset) as f:\n",
    "        for line in f:\n",
    "            doc = line.split()\n",
    "            t = doc[1]\n",
    "            F = []\n",
    "            for i in doc[2:]:\n",
    "                F.append(int(i))\n",
    "            score = spamminess(F,model)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            for f in F:\n",
    "                if t == 'spam':\n",
    "                    if f not in model:\n",
    "                        model[f] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model[f] += (1.0-prob)*delta\n",
    "                elif t == 'ham':\n",
    "                    if f not in model:\n",
    "                        model[f] = -prob*delta\n",
    "                    else:\n",
    "                        model[f] -= prob*delta\n",
    "        \n",
    "    #   for line in f:\n",
    "    #      each line represents a document\n",
    "    #      read and parse the line\n",
    "    #      Let:\n",
    "    #        t represent the spam/ham tag for this document\n",
    "    #        F represent the list of features for this document\n",
    "\n",
    "    #      find the spamminess of the current document using the current model:\n",
    "    #      score = spamminess(F,w)\n",
    "\n",
    "    #      then, update the model:\n",
    "    #      prob = 1.0/(1+exp(-score))\n",
    "    #      for each feature f in F:\n",
    "    #          if t == 'spam':\n",
    "    #              increase model(f) by (1.0-prob)*delta (or set model(f) to (1.0-prob)*delta if f is not in the dict yet)\n",
    "    #          elif t == 'ham':\n",
    "    #              decrease model(f) by prob*delta (or set model(f) to -prob*delta if f is not in the dict yet)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# tests here\n",
    "w = sequential_SGD({}) # Providing an empty model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Part 2:\n",
    "\n",
    "Try implementing a Spark version of the SGD model trainer.   Before we start, create a new folder\n",
    "called `models` inside the cs631 folder.   The Spark implementation should read a training file, train the model, and then output the model to the models folder.  The model output file should list the weight associated with each feature, with one feature per line, like this:\n",
    "```\n",
    "(802123, 0.0009858585991850937)\n",
    "(438450, 4.267897922108138e-05)\n",
    "(271525, 0.0013133437007968654)\n",
    "(92853, 0.0004300009932503611)\n",
    "```\n",
    "\n",
    "\n",
    "Implement the function `spark_SGD()` below that takes as input the path to the training dataset, an output path `output_model` and a value for the update parameter `delta`, and writes the trained model to `output_model` using Spark's `saveAsTextFile`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "import shutil, os\n",
    "\n",
    "def spark_SGD(training_dataset='/u/cs451/public_html/spam/spam.train.group_x.txt', output_model='models/group_x_model', delta = 0.002):\n",
    "    if os.path.isdir(output_model):\n",
    "        shutil.rmtree(output_model) # Remove the previous model to create a new one\n",
    "    training_data = sc.textFile(training_dataset) \n",
    "    # split the data and force all of the training instances into a single partition\n",
    "    training_data_new = training_data.map(lambda x:x.split()).repartition(1)    \n",
    "    # define a function that update the model weights\n",
    "    def update_weight(x):\n",
    "        model = {}\n",
    "        for line in x:\n",
    "            t = line[1]\n",
    "            F = []\n",
    "            for i in line[2:]:\n",
    "                F.append(int(i))\n",
    "            score = spamminess(F,model)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            for f in F:\n",
    "                if t == 'spam':\n",
    "                    if f not in model:\n",
    "                        model[f] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model[f] += (1.0-prob)*delta\n",
    "                elif t == 'ham':\n",
    "                    if f not in model:\n",
    "                        model[f] = -prob*delta\n",
    "                    else:\n",
    "                        model[f] -= prob*delta\n",
    "        return model.items()\n",
    "    # use mapPartitions to call the above function and get the desired output\n",
    "    final_model = training_data_new.mapPartitions(update_weight).map(lambda x:(x[0],x[1]))\n",
    "    final_model.saveAsTextFile(output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# tests here\n",
    "spark_SGD()\n",
    "spark_SGD(training_dataset='/u/cs451/public_html/spam/spam.train.group_y.txt', output_model='models/group_y_model')\n",
    "spark_SGD(training_dataset='/u/cs451/public_html/spam/spam.train.britney.txt', output_model='models/britney_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Part 3:\n",
    "\n",
    "Re-implement the trainer from part 2 so that it will randomly reorder the training instances before using them to update the model. One way to shuffle the training instances is to assign a random sort key to each training instance as we read it from the input file, and then sort the instances using the random sort key.\n",
    "\n",
    "Implement the function `spark_shuffled_SGD` below that takes as input the path to the training dataset, an output path `output_model` and a value for the update parameter `delta`, shuffles the training instances using the method described above and writes the trained model to `output_model` using Spark's `saveAsTextFile`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "import shutil, os, random\n",
    "\n",
    "def spark_shuffled_SGD(training_dataset='/u/cs451/public_html/spam/spam.train.group_x.txt', output_model='models/group_x_model', delta = 0.002):\n",
    "    if os.path.isdir(output_model):\n",
    "        shutil.rmtree(output_model) # Remove the previous model to create a new one\n",
    "    training_data = sc.textFile(training_dataset)\n",
    "    # split the data and force all of the training instances into a single partition\n",
    "    # also, assign a random key to each training instance and shuffle the training instances\n",
    "    training_data_new = training_data.map(lambda x:x.split()).repartition(1)\\\n",
    "                        .map(lambda x:(random.random(),x)).sortByKey(True).map(lambda x:x[1])\n",
    "    # define a function that update the model weights\n",
    "    def update_weight(x):\n",
    "        model = {}\n",
    "        for line in x:\n",
    "            t = line[1]\n",
    "            F = []\n",
    "            for i in line[2:]:\n",
    "                F.append(int(i))\n",
    "            score = spamminess(F,model)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            for f in F:\n",
    "                if t == 'spam':\n",
    "                    if f not in model:\n",
    "                        model[f] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model[f] += (1.0-prob)*delta\n",
    "                elif t == 'ham':\n",
    "                    if f not in model:\n",
    "                        model[f] = -prob*delta\n",
    "                    else:\n",
    "                        model[f] -= prob*delta\n",
    "        return model.items()\n",
    "    # use mapPartitions to call the above function and get the desired output\n",
    "    final_model = training_data_new.mapPartitions(update_weight).map(lambda x:(x[0],x[1]))\n",
    "    final_model.saveAsTextFile(output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional part - Comparison between the models in Part 2 and Part 3 ###\n",
    "Based on the codes in the following cell:  \n",
    "a) Most of the 5 features with the highest weights are different in the original model and the shuffled model, although the weight values are similar.  \n",
    "b) The ROCA score of the two models are similar.  \n",
    "To sum up, shuffling the training instances does have some effect on the training model, but the overall accuracy does not change a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 features with the highest weights in the original model are\n",
      "[(288281, 0.022996007768337472), (316070, 0.02178760768974702), (305568, 0.02166991395934579), (737304, 0.02155627086676939), (102264, 0.021381723804112546)]\n",
      "The ROCA of the original model is\n",
      "1-ROCA%: 17.26\n",
      "The 5 features with the highest weights in the shuffled model are\n",
      "[(278969, 0.024026215713269107), (275149, 0.023040579273347354), (943477, 0.02284840305297022), (944342, 0.022367091269665434), (288281, 0.0223646197909275)]\n",
      "The ROCA of the shuffled model is\n",
      "1-ROCA%: 17.94\n"
     ]
    }
   ],
   "source": [
    "# tests here (!!! run this cell as the last step !!!)\n",
    "# the original model in part2\n",
    "spark_SGD(output_model='models/group_x_model')\n",
    "top5_weights = sc.textFile('models/group_x_model').map(lambda x:eval(x))\\\n",
    "               .map(lambda x:(x[1],x[0])).sortByKey(False).map(lambda x:(x[1],x[0])).take(5)\n",
    "print(\"The 5 features with the highest weights in the original model are\")\n",
    "print(top5_weights)\n",
    "spark_classify(input_model='models/group_x_model')\n",
    "print(\"The ROCA of the original model is\")\n",
    "!/u/cs451/bin/spam_eval.sh results/test_qrels\n",
    "\n",
    "# the shuffled model in part3\n",
    "spark_shuffled_SGD(output_model='models/group_x_model_shuffled')\n",
    "top5_weights_shuffled = sc.textFile('models/group_x_model_shuffled').map(lambda x:eval(x))\\\n",
    "                        .map(lambda x:(x[1],x[0])).sortByKey(False).map(lambda x:(x[1],x[0])).take(5)\n",
    "print(\"The 5 features with the highest weights in the shuffled model are\")\n",
    "print(top5_weights_shuffled)\n",
    "spark_classify(input_model='models/group_x_model_shuffled')\n",
    "print(\"The ROCA of the shuffled model is\")\n",
    "!/u/cs451/bin/spam_eval.sh results/test_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Part 4:\n",
    "\n",
    "Last but not least, write a Spark program that can be used to classify documents as spam or ham, using the classification models we produced.\n",
    "\n",
    "The test data, i.e., the document instances that should be classified, are located in the file\n",
    "* `/u/cs451/public_html/spam/spam.test.qrels.txt`\n",
    "\n",
    "Each line in this file represents a document that needs to be classified as spam or ham.  The format of this file is identical to the format of the files that hold the training instances.\n",
    "\n",
    "Implement the function `spark_classify` below that will load a model (from a specified folder under `models`), classify all of the instances in a given test data file (`spam.test.qrels.txt` by default) using that model, and then output the results in the folder `results_path` using Spark's `saveAsTextFile`.   The contents of the output file should look like this:\n",
    "```\n",
    "(clueweb09-en0000-00-00142,spam,2.601624279252943,spam)\n",
    "(clueweb09-en0000-00-01005,ham,2.5654162439491004,spam)\n",
    "(clueweb09-en0000-00-01382,ham,2.5893946346394188,spam)\n",
    "```\n",
    "Each line of the output represents one test instance.   The first two fields are the document ID and the test label.  These are just copied from the test data.   The third field is the spamminess score of the document, produced by the spamminess function using the model we are classifying with.   The fourth field is the spam/ham prediction made by the model.\n",
    "\n",
    "Unlike model training, classification is easily parallelizable, since each document is classified independently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "import shutil, os\n",
    "\n",
    "def spark_classify(input_model='models/group_x_model', test_dataset='/u/cs451/public_html/spam/spam.test.qrels.txt', results_path='results/test_qrels'):\n",
    "    if os.path.isdir(results_path):\n",
    "        shutil.rmtree(results_path) # Remove the previous results\n",
    "    test_data = sc.textFile(test_dataset)\n",
    "    # load the training model into the driver program as side data\n",
    "    model_weights = sc.textFile(input_model).map(lambda x:eval(x)).collect()\n",
    "    # transform the model into the dictionary to match the parameter format in spamminess calculation\n",
    "    model_dict = dict(model_weights)\n",
    "    # split and rearrange the test data\n",
    "    test_data_new = test_data.map(lambda x:x.split()).map(lambda x:(x[0],x[1],[int(x[i]) for i in range(2,len(x))]))\n",
    "    # calculate the spamminess score of each instance in test data\n",
    "    test_score = test_data_new.map(lambda x:(x[0],x[1],spamminess(x[2],model_dict)))\n",
    "    # predict whether it is 'spam' or 'ham' based on the spamminess score, and rearrange the data to a desired output\n",
    "    test_prediction = test_score.map(lambda x:(x[0],x[1],x[2],'spam' if x[2] >= 0 else 'ham'))  \n",
    "    test_prediction.saveAsTextFile(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "We have installed a program in the CS451 account that can be used to evaluate our classification results.  Given the ouput file, in the proper format, it will compute the area under the receiver operating curve (ROC).   This is a common way to characterize classifier error.    The lower this score, the better.   The evaluation program should produce one line of output, like this\n",
    "```\n",
    "1-ROCA%: 17.25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-ROCA%: 17.26\r\n"
     ]
    }
   ],
   "source": [
    "# tests here\n",
    "#  Run the evaluation program like this, after first replacing \"output-file\"\n",
    "#  with the name of the folder that holds your classifier's output\n",
    "#  Note the \"!\" character, which is important.   This is the escape character\n",
    "#  that tells the notebook to run an external program.\n",
    "spark_classify()\n",
    "!/u/cs451/bin/spam_eval.sh results/test_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
